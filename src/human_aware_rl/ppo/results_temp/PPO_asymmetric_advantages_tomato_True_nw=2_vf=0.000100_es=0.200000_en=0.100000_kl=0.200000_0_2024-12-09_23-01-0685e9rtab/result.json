{"custom_metrics": {"sparse_reward_mean": 0.0, "sparse_reward_min": 0, "sparse_reward_max": 0, "shaped_reward_mean": 1.5, "shaped_reward_min": 0, "shaped_reward_max": 3, "tomato_pickup_agent_0_mean": 0.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 1, "tomato_pickup_agent_1_mean": 3.0, "tomato_pickup_agent_1_min": 2, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 1, "useful_tomato_pickup_agent_1_mean": 3.0, "useful_tomato_pickup_agent_1_min": 2, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.0, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 2, "tomato_drop_agent_1_mean": 5.0, "tomato_drop_agent_1_min": 4, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 0, "useful_tomato_drop_agent_1_mean": 0.0, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 0, "potting_tomato_agent_0_mean": 0.0, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 0, "potting_tomato_agent_1_mean": 0.0, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 0, "onion_pickup_agent_0_mean": 1.5, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 3, "onion_pickup_agent_1_mean": 4.5, "onion_pickup_agent_1_min": 4, "onion_pickup_agent_1_max": 5, "useful_onion_pickup_agent_0_mean": 1.5, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 3, "useful_onion_pickup_agent_1_mean": 4.5, "useful_onion_pickup_agent_1_min": 4, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 1.0, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 2, "onion_drop_agent_1_mean": 4.0, "onion_drop_agent_1_min": 3, "onion_drop_agent_1_max": 5, "useful_onion_drop_agent_0_mean": 0.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 0, "useful_onion_drop_agent_1_mean": 0.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 0, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 7.5, "dish_pickup_agent_0_min": 7, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 1, "dish_pickup_agent_1_max": 3, "useful_dish_pickup_agent_0_mean": 0.0, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 0, "useful_dish_pickup_agent_1_mean": 0.0, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 0, "dish_drop_agent_0_mean": 7.0, "dish_drop_agent_0_min": 7, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 2.0, "dish_drop_agent_1_min": 1, "dish_drop_agent_1_max": 3, "useful_dish_drop_agent_0_mean": 5.5, "useful_dish_drop_agent_0_min": 5, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.5, "useful_dish_drop_agent_1_min": 1, "useful_dish_drop_agent_1_max": 2, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.0, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 0, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 0, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.0, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 0, "optimal_tomato_potting_agent_1_mean": 0.0, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 0, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.0, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 0, "viable_tomato_potting_agent_1_mean": 0.0, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 0, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.0, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 0, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 4.999999873689376e-05, "total_loss": -0.35742706060409546, "policy_loss": 1.543201506137848e-05, "vf_loss": 7.338449954986572, "vf_explained_var": 0.0002448558807373047, "kl": 3.7933966723358026e-06, "entropy": 1.7908855676651, "entropy_coeff": 0.20000000298023224, "model": {}}}}, "num_env_steps_sampled": 800, "num_env_steps_trained": 800, "num_agent_steps_sampled": 1600, "num_agent_steps_trained": 1600}, "sampler_results": {"episode_reward_max": 1.635813875194458, "episode_reward_min": 0.0, "episode_reward_mean": 0.817906937597229, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0}, "policy_reward_max": {"ppo": 0.817906937597229}, "policy_reward_mean": {"ppo": 0.4089534687986145}, "custom_metrics": {"sparse_reward_mean": 0.0, "sparse_reward_min": 0, "sparse_reward_max": 0, "shaped_reward_mean": 1.5, "shaped_reward_min": 0, "shaped_reward_max": 3, "tomato_pickup_agent_0_mean": 0.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 1, "tomato_pickup_agent_1_mean": 3.0, "tomato_pickup_agent_1_min": 2, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 1, "useful_tomato_pickup_agent_1_mean": 3.0, "useful_tomato_pickup_agent_1_min": 2, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.0, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 2, "tomato_drop_agent_1_mean": 5.0, "tomato_drop_agent_1_min": 4, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 0, "useful_tomato_drop_agent_1_mean": 0.0, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 0, "potting_tomato_agent_0_mean": 0.0, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 0, "potting_tomato_agent_1_mean": 0.0, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 0, "onion_pickup_agent_0_mean": 1.5, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 3, "onion_pickup_agent_1_mean": 4.5, "onion_pickup_agent_1_min": 4, "onion_pickup_agent_1_max": 5, "useful_onion_pickup_agent_0_mean": 1.5, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 3, "useful_onion_pickup_agent_1_mean": 4.5, "useful_onion_pickup_agent_1_min": 4, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 1.0, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 2, "onion_drop_agent_1_mean": 4.0, "onion_drop_agent_1_min": 3, "onion_drop_agent_1_max": 5, "useful_onion_drop_agent_0_mean": 0.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 0, "useful_onion_drop_agent_1_mean": 0.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 0, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 7.5, "dish_pickup_agent_0_min": 7, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 1, "dish_pickup_agent_1_max": 3, "useful_dish_pickup_agent_0_mean": 0.0, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 0, "useful_dish_pickup_agent_1_mean": 0.0, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 0, "dish_drop_agent_0_mean": 7.0, "dish_drop_agent_0_min": 7, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 2.0, "dish_drop_agent_1_min": 1, "dish_drop_agent_1_max": 3, "useful_dish_drop_agent_0_mean": 5.5, "useful_dish_drop_agent_0_min": 5, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.5, "useful_dish_drop_agent_1_min": 1, "useful_dish_drop_agent_1_max": 2, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.0, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 0, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 0, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.0, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 0, "optimal_tomato_potting_agent_1_mean": 0.0, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 0, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.0, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 0, "viable_tomato_potting_agent_1_mean": 0.0, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 0, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.0, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 0, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458], "episode_lengths": [400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43759114129882204, "mean_inference_ms": 2.5057718343568265, "mean_action_processing_ms": 0.033784091026705695, "mean_env_wait_ms": 0.7081046663317598, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 1.635813875194458, "episode_reward_min": 0.0, "episode_reward_mean": 0.817906937597229, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0}, "policy_reward_max": {"ppo": 0.817906937597229}, "policy_reward_mean": {"ppo": 0.4089534687986145}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458], "episode_lengths": [400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.43759114129882204, "mean_inference_ms": 2.5057718343568265, "mean_action_processing_ms": 0.033784091026705695, "mean_env_wait_ms": 0.7081046663317598, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 1600, "num_agent_steps_trained": 1600, "num_env_steps_sampled": 800, "num_env_steps_trained": 800, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 800, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 1600, "timers": {"training_iteration_time_ms": 1938.069, "learn_time_ms": 417.973, "learn_throughput": 1913.999, "synch_weights_time_ms": 26.387}, "counters": {"num_env_steps_sampled": 800, "num_env_steps_trained": 800, "num_agent_steps_sampled": 1600, "num_agent_steps_trained": 1600}, "done": false, "episodes_total": 2, "training_iteration": 1, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-01-50", "timestamp": 1733745710, "time_this_iter_s": 1.9410731792449951, "time_total_s": 1.9410731792449951, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 1.9410731792449951, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 27.066666666666666, "ram_util_percent": 75.16666666666667}}
{"custom_metrics": {"sparse_reward_mean": 0.0, "sparse_reward_min": 0, "sparse_reward_max": 0, "shaped_reward_mean": 2.25, "shaped_reward_min": 0, "shaped_reward_max": 3, "tomato_pickup_agent_0_mean": 0.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 1, "tomato_pickup_agent_1_mean": 3.5, "tomato_pickup_agent_1_min": 2, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 1, "useful_tomato_pickup_agent_1_mean": 3.0, "useful_tomato_pickup_agent_1_min": 2, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 0.75, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 2, "tomato_drop_agent_1_mean": 5.25, "tomato_drop_agent_1_min": 4, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 0, "useful_tomato_drop_agent_1_mean": 0.75, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 3, "potting_tomato_agent_0_mean": 0.25, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.0, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 0, "onion_pickup_agent_0_mean": 2.75, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 2.75, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 5, "useful_onion_pickup_agent_0_mean": 2.25, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.75, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 2.25, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.0, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 5, "useful_onion_drop_agent_0_mean": 0.5, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 2, "useful_onion_drop_agent_1_mean": 0.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 0, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 6.25, "dish_pickup_agent_0_min": 3, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 2.5, "dish_pickup_agent_1_min": 1, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.0, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 0, "useful_dish_pickup_agent_1_mean": 0.0, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 0, "dish_drop_agent_0_mean": 6.0, "dish_drop_agent_0_min": 3, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 2.5, "dish_drop_agent_1_min": 1, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 4.5, "useful_dish_drop_agent_0_min": 1, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 2.0, "useful_dish_drop_agent_1_min": 1, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.0, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 0, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 0, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.25, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.0, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 0, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.25, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.0, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 0, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.0, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 0, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.10000000149011612, "cur_lr": 4.999999873689376e-05, "total_loss": -0.35657018423080444, "policy_loss": -1.666974276304245e-05, "vf_loss": 6.4236345291137695, "vf_explained_var": -3.269314765930176e-05, "kl": 4.0989843341776577e-07, "entropy": 1.790755271911621, "entropy_coeff": 0.19946666061878204, "model": {}}}}, "num_env_steps_sampled": 1600, "num_env_steps_trained": 1600, "num_agent_steps_sampled": 3200, "num_agent_steps_trained": 3200}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 30.610586115774176, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0}, "policy_reward_max": {"ppo": 59.58535835635389}, "policy_reward_mean": {"ppo": 15.305293057887088}, "custom_metrics": {"sparse_reward_mean": 0.0, "sparse_reward_min": 0, "sparse_reward_max": 0, "shaped_reward_mean": 2.25, "shaped_reward_min": 0, "shaped_reward_max": 3, "tomato_pickup_agent_0_mean": 0.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 1, "tomato_pickup_agent_1_mean": 3.5, "tomato_pickup_agent_1_min": 2, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 1, "useful_tomato_pickup_agent_1_mean": 3.0, "useful_tomato_pickup_agent_1_min": 2, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 0.75, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 2, "tomato_drop_agent_1_mean": 5.25, "tomato_drop_agent_1_min": 4, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 0, "useful_tomato_drop_agent_1_mean": 0.75, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 3, "potting_tomato_agent_0_mean": 0.25, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.0, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 0, "onion_pickup_agent_0_mean": 2.75, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 2.75, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 5, "useful_onion_pickup_agent_0_mean": 2.25, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.75, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 2.25, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.0, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 5, "useful_onion_drop_agent_0_mean": 0.5, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 2, "useful_onion_drop_agent_1_mean": 0.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 0, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 6.25, "dish_pickup_agent_0_min": 3, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 2.5, "dish_pickup_agent_1_min": 1, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.0, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 0, "useful_dish_pickup_agent_1_mean": 0.0, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 0, "dish_drop_agent_0_mean": 6.0, "dish_drop_agent_0_min": 3, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 2.5, "dish_drop_agent_1_min": 1, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 4.5, "useful_dish_drop_agent_0_min": 1, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 2.0, "useful_dish_drop_agent_1_min": 1, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.0, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 0, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 0, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.25, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.0, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 0, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.25, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.0, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 0, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.0, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 0, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779], "episode_lengths": [400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4254000031733313, "mean_inference_ms": 2.3392172537153684, "mean_action_processing_ms": 0.0423532001463022, "mean_env_wait_ms": 0.6930312404569445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 30.610586115774176, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0}, "policy_reward_max": {"ppo": 59.58535835635389}, "policy_reward_mean": {"ppo": 15.305293057887088}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779], "episode_lengths": [400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4254000031733313, "mean_inference_ms": 2.3392172537153684, "mean_action_processing_ms": 0.0423532001463022, "mean_env_wait_ms": 0.6930312404569445, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 3200, "num_agent_steps_trained": 3200, "num_env_steps_sampled": 1600, "num_env_steps_trained": 1600, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 1600, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 3200, "timers": {"training_iteration_time_ms": 1581.233, "learn_time_ms": 217.932, "learn_throughput": 3670.876, "synch_weights_time_ms": 14.737}, "counters": {"num_env_steps_sampled": 1600, "num_env_steps_trained": 1600, "num_agent_steps_sampled": 3200, "num_agent_steps_trained": 3200}, "done": false, "episodes_total": 4, "training_iteration": 2, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-01-51", "timestamp": 1733745711, "time_this_iter_s": 1.2303965091705322, "time_total_s": 3.1714696884155273, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 3.1714696884155273, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 24.55, "ram_util_percent": 76.25}}
{"custom_metrics": {"sparse_reward_mean": 0.0, "sparse_reward_min": 0, "sparse_reward_max": 0, "shaped_reward_mean": 4.0, "shaped_reward_min": 0, "shaped_reward_max": 9, "tomato_pickup_agent_0_mean": 0.8333333333333334, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 2, "tomato_pickup_agent_1_mean": 3.3333333333333335, "tomato_pickup_agent_1_min": 2, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 1, "useful_tomato_pickup_agent_1_mean": 2.1666666666666665, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.1666666666666667, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 3, "tomato_drop_agent_1_mean": 4.833333333333333, "tomato_drop_agent_1_min": 3, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.6666666666666666, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 3, "useful_tomato_drop_agent_1_mean": 1.5, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.3333333333333333, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.16666666666666666, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 3.3333333333333335, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.3333333333333335, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 5, "useful_onion_pickup_agent_0_mean": 2.3333333333333335, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.5, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 3.0, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.5, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 5, "useful_onion_drop_agent_0_mean": 1.3333333333333333, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 0.8333333333333334, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 3, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.6666666666666666, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 4.166666666666667, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.0, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 0, "useful_dish_pickup_agent_1_mean": 0.16666666666666666, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 4.0, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.8333333333333333, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 3.0, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.3333333333333333, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.0, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 0, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 0, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.6666666666666666, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.3333333333333333, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.0, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 0, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.6666666666666666, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.3333333333333333, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.0, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 0, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.16666666666666666, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.05000000074505806, "cur_lr": 4.999999873689376e-05, "total_loss": -0.35577714443206787, "policy_loss": -1.0579824447631836e-05, "vf_loss": 3.890044689178467, "vf_explained_var": -0.00030153989791870117, "kl": 2.2044407899102225e-07, "entropy": 1.7903262376785278, "entropy_coeff": 0.19893333315849304, "model": {}}}}, "num_env_steps_sampled": 2400, "num_env_steps_trained": 2400, "num_agent_steps_sampled": 4800, "num_agent_steps_trained": 4800}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 20.975154680287236, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0}, "policy_reward_max": {"ppo": 59.58535835635389}, "policy_reward_mean": {"ppo": 10.487577340143618}, "custom_metrics": {"sparse_reward_mean": 0.0, "sparse_reward_min": 0, "sparse_reward_max": 0, "shaped_reward_mean": 4.0, "shaped_reward_min": 0, "shaped_reward_max": 9, "tomato_pickup_agent_0_mean": 0.8333333333333334, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 2, "tomato_pickup_agent_1_mean": 3.3333333333333335, "tomato_pickup_agent_1_min": 2, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 1, "useful_tomato_pickup_agent_1_mean": 2.1666666666666665, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.1666666666666667, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 3, "tomato_drop_agent_1_mean": 4.833333333333333, "tomato_drop_agent_1_min": 3, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.6666666666666666, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 3, "useful_tomato_drop_agent_1_mean": 1.5, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.3333333333333333, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.16666666666666666, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 3.3333333333333335, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.3333333333333335, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 5, "useful_onion_pickup_agent_0_mean": 2.3333333333333335, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.5, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 3.0, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.5, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 5, "useful_onion_drop_agent_0_mean": 1.3333333333333333, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 0.8333333333333334, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 3, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.6666666666666666, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 4.166666666666667, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.0, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 0, "useful_dish_pickup_agent_1_mean": 0.16666666666666666, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 4.0, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.8333333333333333, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 3.0, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.3333333333333333, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.0, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 0, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 0, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.6666666666666666, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.3333333333333333, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.0, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 0, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.6666666666666666, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.3333333333333333, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.0, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 0, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.16666666666666666, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636], "episode_lengths": [400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4215775254534126, "mean_inference_ms": 2.2451812188342766, "mean_action_processing_ms": 0.047038738752120744, "mean_env_wait_ms": 0.6950948397149389, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 20.975154680287236, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0}, "policy_reward_max": {"ppo": 59.58535835635389}, "policy_reward_mean": {"ppo": 10.487577340143618}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636], "episode_lengths": [400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4215775254534126, "mean_inference_ms": 2.2451812188342766, "mean_action_processing_ms": 0.047038738752120744, "mean_env_wait_ms": 0.6950948397149389, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 4800, "num_agent_steps_trained": 4800, "num_env_steps_sampled": 2400, "num_env_steps_trained": 2400, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 2400, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 4800, "timers": {"training_iteration_time_ms": 1473.2, "learn_time_ms": 153.341, "learn_throughput": 5217.142, "synch_weights_time_ms": 10.825}, "counters": {"num_env_steps_sampled": 2400, "num_env_steps_trained": 2400, "num_agent_steps_sampled": 4800, "num_agent_steps_trained": 4800}, "done": false, "episodes_total": 6, "training_iteration": 3, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-01-53", "timestamp": 1733745713, "time_this_iter_s": 1.26251220703125, "time_total_s": 4.433981895446777, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 4.433981895446777, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 28.9, "ram_util_percent": 76.3}}
{"custom_metrics": {"sparse_reward_mean": 1.625, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 5.5, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.375, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.75, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.625, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 2, "useful_tomato_pickup_agent_1_mean": 1.75, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.75, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 4.0, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 3, "useful_tomato_drop_agent_1_mean": 1.25, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.375, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.25, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.75, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.75, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 8, "useful_onion_pickup_agent_0_mean": 1.75, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.125, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 2.5, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.75, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 6, "useful_onion_drop_agent_0_mean": 1.25, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.5, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.75, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.875, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 1.625, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.125, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.125, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 3.75, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.375, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 2.375, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.125, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.125, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.75, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.375, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.125, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.75, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.375, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.125, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.125, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.02500000037252903, "cur_lr": 4.999999873689376e-05, "total_loss": -0.35357820987701416, "policy_loss": 0.0013014196883887053, "vf_loss": 3.3234710693359375, "vf_explained_var": -0.00024837255477905273, "kl": 2.318963794323281e-07, "entropy": 1.7903828620910645, "entropy_coeff": 0.19840000569820404, "model": {}}}}, "num_env_steps_sampled": 3200, "num_env_steps_trained": 3200, "num_agent_steps_sampled": 6400, "num_agent_steps_trained": 6400}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 19.390319479014043, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 13.817906937597229}, "policy_reward_mean": {"ppo": 9.420309926301007, "bc": 13.817906937597229}, "custom_metrics": {"sparse_reward_mean": 1.625, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 5.5, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.375, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.75, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.625, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 2, "useful_tomato_pickup_agent_1_mean": 1.75, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.75, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 4.0, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 3, "useful_tomato_drop_agent_1_mean": 1.25, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.375, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.25, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.75, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.75, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 8, "useful_onion_pickup_agent_0_mean": 1.75, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.125, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 2.5, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.75, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 6, "useful_onion_drop_agent_0_mean": 1.25, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.5, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.75, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.875, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 1.625, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.125, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.125, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 3.75, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.375, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 2.375, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.0, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 0, "soup_pickup_agent_1_mean": 0.125, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.125, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.0, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 0, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.75, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.375, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.125, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.75, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.375, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.125, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.125, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229], "policy_bc_reward": [13.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4216307412541873, "mean_inference_ms": 2.2322939172948084, "mean_action_processing_ms": 0.05165480661975187, "mean_env_wait_ms": 0.701836067496177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 19.390319479014043, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 13.817906937597229}, "policy_reward_mean": {"ppo": 9.420309926301007, "bc": 13.817906937597229}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229], "policy_bc_reward": [13.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4216307412541873, "mean_inference_ms": 2.2322939172948084, "mean_action_processing_ms": 0.05165480661975187, "mean_env_wait_ms": 0.701836067496177, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 6400, "num_agent_steps_trained": 6400, "num_env_steps_sampled": 3200, "num_env_steps_trained": 3200, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 3200, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 6400, "timers": {"training_iteration_time_ms": 1605.051, "learn_time_ms": 129.437, "learn_throughput": 6180.634, "synch_weights_time_ms": 9.12}, "counters": {"num_env_steps_sampled": 3200, "num_env_steps_trained": 3200, "num_agent_steps_sampled": 6400, "num_agent_steps_trained": 6400}, "done": false, "episodes_total": 8, "training_iteration": 4, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-01-55", "timestamp": 1733745715, "time_this_iter_s": 2.0006027221679688, "time_total_s": 6.434584617614746, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 6.434584617614746, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 29.100000000000005, "ram_util_percent": 76.0}}
{"evaluation": {"average_sparse_reward": 0.0, "num_healthy_workers": 0, "num_recreated_workers": 0}, "custom_metrics": {"sparse_reward_mean": 1.3, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 6.1, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.6, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.6, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 2, "useful_tomato_pickup_agent_1_mean": 1.5, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.2, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.8, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.5, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.6, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.3, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.3, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.3, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.7, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 8, "useful_onion_pickup_agent_0_mean": 1.5, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.9, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 2.1, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.8, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 6, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.7, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.7, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.4, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 1.5, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.2, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.2, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 3.2, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.3, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.9, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.8, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.1, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.1, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.1, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.7, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.3, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.2, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.7, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.3, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.2, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.1, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.012500000186264515, "cur_lr": 4.999999873689376e-05, "total_loss": -0.35398197174072266, "policy_loss": 1.3062264770269394e-05, "vf_loss": 3.322619915008545, "vf_explained_var": 0.00011858344078063965, "kl": 1.212774947134676e-07, "entropy": 1.7907376289367676, "entropy_coeff": 0.19786666333675385, "model": {}}}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 19.82389259420472, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 13.817906937597229}, "policy_reward_mean": {"ppo": 9.706369421286842, "bc": 13.817906937597229}, "custom_metrics": {"sparse_reward_mean": 1.3, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 6.1, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.6, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.6, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 2, "useful_tomato_pickup_agent_1_mean": 1.5, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.2, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.8, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.5, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.6, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.3, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 1, "potting_tomato_agent_1_mean": 0.3, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.3, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.7, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 8, "useful_onion_pickup_agent_0_mean": 1.5, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.9, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 5, "onion_drop_agent_0_mean": 2.1, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.8, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 6, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.7, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.7, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.4, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 1.5, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 4, "useful_dish_pickup_agent_0_mean": 0.2, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.2, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 3.2, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.3, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.9, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.8, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.1, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.1, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.1, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.0, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 0, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.7, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.3, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 1, "optimal_tomato_potting_agent_1_mean": 0.2, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.7, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.3, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 1, "viable_tomato_potting_agent_1_mean": 0.2, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.1, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229], "policy_bc_reward": [13.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4194263772459636, "mean_inference_ms": 2.208657436978709, "mean_action_processing_ms": 0.054864054618477806, "mean_env_wait_ms": 0.7112269150680296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 19.82389259420472, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 13.817906937597229}, "policy_reward_mean": {"ppo": 9.706369421286842, "bc": 13.817906937597229}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229], "policy_bc_reward": [13.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4194263772459636, "mean_inference_ms": 2.208657436978709, "mean_action_processing_ms": 0.054864054618477806, "mean_env_wait_ms": 0.7112269150680296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 4000, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 1539.376, "learn_time_ms": 106.934, "learn_throughput": 7481.255, "synch_weights_time_ms": 7.808}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 10, "training_iteration": 5, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-01-58", "timestamp": 1733745718, "time_this_iter_s": 2.9396708011627197, "time_total_s": 9.374255418777466, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 9.374255418777466, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 21.325, "ram_util_percent": 75.85000000000001}}
{"custom_metrics": {"sparse_reward_mean": 1.0833333333333333, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 6.5, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.5833333333333335, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.75, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.6666666666666667, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.25, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.75, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.25, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.3333333333333333, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.5, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.25, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.0, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 4.083333333333333, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.3333333333333333, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.5, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.75, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 3.1666666666666665, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.8333333333333334, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.5, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.6666666666666666, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.9166666666666665, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 1.75, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.16666666666666666, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.16666666666666666, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.6666666666666665, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.4166666666666667, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.5833333333333333, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.8333333333333334, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.08333333333333333, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.16666666666666666, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.08333333333333333, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08333333333333333, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.08333333333333333, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.6666666666666666, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.4166666666666667, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.16666666666666666, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.6666666666666666, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.16666666666666666, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.08333333333333333, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.0062500000931322575, "cur_lr": 4.999999873689376e-05, "total_loss": -0.3644998073577881, "policy_loss": -0.01191978994756937, "vf_loss": 7.523509502410889, "vf_explained_var": -0.0005438923835754395, "kl": 1.5898994831786695e-07, "entropy": 1.7905354499816895, "entropy_coeff": 0.19733333587646484, "model": {}}}}, "num_env_steps_sampled": 4800, "num_env_steps_trained": 4800, "num_agent_steps_sampled": 9600, "num_agent_steps_trained": 9600}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 36.38169661395523, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 16.508049730614164, "bc": 36.70163264697556}, "custom_metrics": {"sparse_reward_mean": 1.0833333333333333, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 6.5, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.5, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.5833333333333335, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.75, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.6666666666666667, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.25, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.75, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.25, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.3333333333333333, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.5, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.25, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.0, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 4.083333333333333, "onion_pickup_agent_1_min": 1, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.3333333333333333, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.5, "useful_onion_pickup_agent_1_min": 1, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.75, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 3.1666666666666665, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.8333333333333334, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.5, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.6666666666666666, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.9166666666666665, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 8, "dish_pickup_agent_1_mean": 1.75, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.16666666666666666, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.16666666666666666, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.6666666666666665, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 7, "dish_drop_agent_1_mean": 1.4166666666666667, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.5833333333333333, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.8333333333333334, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 3, "soup_pickup_agent_0_mean": 0.08333333333333333, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.16666666666666666, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.08333333333333333, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08333333333333333, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.08333333333333333, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.6666666666666666, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.4166666666666667, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.16666666666666666, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.6666666666666666, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.16666666666666666, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.08333333333333333, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389], "policy_bc_reward": [13.817906937597229, 59.58535835635389]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4179799553441715, "mean_inference_ms": 2.211217391267633, "mean_action_processing_ms": 0.05759696815353676, "mean_env_wait_ms": 0.7258569276848196, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 36.38169661395523, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 16.508049730614164, "bc": 36.70163264697556}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389], "policy_bc_reward": [13.817906937597229, 59.58535835635389]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4179799553441715, "mean_inference_ms": 2.211217391267633, "mean_action_processing_ms": 0.05759696815353676, "mean_env_wait_ms": 0.7258569276848196, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 9600, "num_agent_steps_trained": 9600, "num_env_steps_sampled": 4800, "num_env_steps_trained": 4800, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 4800, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 9600, "timers": {"training_iteration_time_ms": 1636.041, "learn_time_ms": 92.473, "learn_throughput": 8651.186, "synch_weights_time_ms": 7.1}, "counters": {"num_env_steps_sampled": 4800, "num_env_steps_trained": 4800, "num_agent_steps_sampled": 9600, "num_agent_steps_trained": 9600}, "done": false, "episodes_total": 12, "training_iteration": 6, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-00", "timestamp": 1733745720, "time_this_iter_s": 2.119364023208618, "time_total_s": 11.493619441986084, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 11.493619441986084, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 24.2, "ram_util_percent": 75.8}}
{"custom_metrics": {"sparse_reward_mean": 0.9285714285714286, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 5.785714285714286, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.3571428571428572, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.5, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.7142857142857143, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.6428571428571428, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.142857142857143, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.7142857142857144, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0714285714285714, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.2857142857142858, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.42857142857142855, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.2857142857142857, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.357142857142857, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.5714285714285716, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.4285714285714286, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.2142857142857144, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.0714285714285716, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.7857142857142856, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.2857142857142858, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5714285714285714, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.2142857142857144, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 2.142857142857143, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.14285714285714285, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.14285714285714285, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 3.0, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.7857142857142858, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.5, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.07142857142857142, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.14285714285714285, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.07142857142857142, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.07142857142857142, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.07142857142857142, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5714285714285714, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.35714285714285715, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.21428571428571427, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5714285714285714, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.42857142857142855, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.21428571428571427, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.07142857142857142, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.0031250000465661287, "cur_lr": 4.999999873689376e-05, "total_loss": -0.35203686356544495, "policy_loss": 2.183951437473297e-06, "vf_loss": 3.8343873023986816, "vf_explained_var": -0.0005443692207336426, "kl": 1.6393721580243437e-07, "entropy": 1.790764570236206, "entropy_coeff": 0.19679999351501465, "model": {}}}}, "num_env_steps_sampled": 5600, "num_env_steps_trained": 5600, "num_agent_steps_sampled": 11200, "num_agent_steps_trained": 11200}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 35.08412426128745, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 16.068249014002813, "bc": 36.70163264697556}, "custom_metrics": {"sparse_reward_mean": 0.9285714285714286, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 5.785714285714286, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.3571428571428572, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.5, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.7142857142857143, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.6428571428571428, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.142857142857143, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.7142857142857144, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0714285714285714, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.2857142857142858, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 4, "potting_tomato_agent_0_mean": 0.42857142857142855, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.2857142857142857, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.357142857142857, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.5714285714285716, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.4285714285714286, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.2142857142857144, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.0714285714285716, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.7857142857142856, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.2857142857142858, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5714285714285714, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.2142857142857144, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 2.142857142857143, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.14285714285714285, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.14285714285714285, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 3.0, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.7857142857142858, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.5, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.07142857142857142, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.14285714285714285, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.07142857142857142, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.07142857142857142, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.07142857142857142, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5714285714285714, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.35714285714285715, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.21428571428571427, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5714285714285714, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.42857142857142855, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.21428571428571427, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.07142857142857142, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753], "policy_bc_reward": [13.817906937597229, 59.58535835635389]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4165293298493304, "mean_inference_ms": 2.2056657322053606, "mean_action_processing_ms": 0.06040883698921522, "mean_env_wait_ms": 0.7363484713246861, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 35.08412426128745, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 13.817906937597229}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 16.068249014002813, "bc": 36.70163264697556}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753], "policy_bc_reward": [13.817906937597229, 59.58535835635389]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4165293298493304, "mean_inference_ms": 2.2056657322053606, "mean_action_processing_ms": 0.06040883698921522, "mean_env_wait_ms": 0.7363484713246861, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 11200, "num_agent_steps_trained": 11200, "num_env_steps_sampled": 5600, "num_env_steps_trained": 5600, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 5600, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 11200, "timers": {"training_iteration_time_ms": 1592.127, "learn_time_ms": 82.184, "learn_throughput": 9734.274, "synch_weights_time_ms": 6.515}, "counters": {"num_env_steps_sampled": 5600, "num_env_steps_trained": 5600, "num_agent_steps_sampled": 11200, "num_agent_steps_trained": 11200}, "done": false, "episodes_total": 14, "training_iteration": 7, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-01", "timestamp": 1733745721, "time_this_iter_s": 1.3376450538635254, "time_total_s": 12.83126449584961, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 12.83126449584961, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 28.25, "ram_util_percent": 75.9}}
{"custom_metrics": {"sparse_reward_mean": 0.8125, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 5.625, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.1875, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.5, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.625, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.625, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.9375, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.8125, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.4375, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.4375, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.25, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.0625, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.3125, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.25, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.0, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.8125, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.5625, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.875, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.25, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5625, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.0, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.1875, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.125, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.6875, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.6875, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.375, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.0625, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.125, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0625, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.0625, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.0625, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5625, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.375, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.1875, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5625, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.4375, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.1875, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.0625, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.0015625000232830644, "cur_lr": 4.999999873689376e-05, "total_loss": -0.3510580360889435, "policy_loss": -5.006789933759137e-07, "vf_loss": 3.0851523876190186, "vf_explained_var": 0.0004118680953979492, "kl": -5.598297381226303e-10, "entropy": 1.7902482748031616, "entropy_coeff": 0.19626666605472565, "model": {}}}}, "num_env_steps_sampled": 6400, "num_env_steps_trained": 6400, "num_agent_steps_sampled": 12800, "num_agent_steps_trained": 12800}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 32.236497672782185, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 15.359913782761373, "bc": 21.426594211799106}, "custom_metrics": {"sparse_reward_mean": 0.8125, "sparse_reward_min": 0, "sparse_reward_max": 13, "shaped_reward_mean": 5.625, "shaped_reward_min": 0, "shaped_reward_max": 17, "tomato_pickup_agent_0_mean": 1.1875, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.5, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.625, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.625, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.9375, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.8125, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.4375, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.4375, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.25, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 2.0625, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.3125, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.25, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 2.0, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.8125, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.5625, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.875, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.25, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.0, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 0, "potting_onion_agent_1_mean": 0.5625, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 3.0, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.1875, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.125, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.6875, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.6875, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.375, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.0625, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 1, "soup_pickup_agent_1_mean": 0.125, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.0, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 0, "soup_delivery_agent_1_mean": 0.0625, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.0625, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.0625, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.0, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 0, "optimal_onion_potting_agent_1_mean": 0.5625, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.375, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.1875, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.0, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 0, "viable_onion_potting_agent_1_mean": 0.5625, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.4375, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.1875, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.0625, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41492505919350425, "mean_inference_ms": 2.225608699073205, "mean_action_processing_ms": 0.06371138718023847, "mean_env_wait_ms": 0.7495034887246348, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 32.236497672782185, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 15.359913782761373, "bc": 21.426594211799106}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41492505919350425, "mean_inference_ms": 2.225608699073205, "mean_action_processing_ms": 0.06371138718023847, "mean_env_wait_ms": 0.7495034887246348, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 12800, "num_agent_steps_trained": 12800, "num_env_steps_sampled": 6400, "num_env_steps_trained": 6400, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 6400, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 12800, "timers": {"training_iteration_time_ms": 1666.947, "learn_time_ms": 72.915, "learn_throughput": 10971.627, "synch_weights_time_ms": 5.7}, "counters": {"num_env_steps_sampled": 6400, "num_env_steps_trained": 6400, "num_agent_steps_sampled": 12800, "num_agent_steps_trained": 12800}, "done": false, "episodes_total": 16, "training_iteration": 8, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-03", "timestamp": 1733745723, "time_this_iter_s": 2.200300693511963, "time_total_s": 15.031565189361572, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 15.031565189361572, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 26.96666666666667, "ram_util_percent": 76.0}}
{"custom_metrics": {"sparse_reward_mean": 2.1666666666666665, "sparse_reward_min": 0, "sparse_reward_max": 26, "shaped_reward_mean": 6.833333333333333, "shaped_reward_min": 0, "shaped_reward_max": 22, "tomato_pickup_agent_0_mean": 1.0555555555555556, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.2222222222222223, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5555555555555556, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.4444444444444444, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.8333333333333333, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.4444444444444446, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8888888888888888, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.2777777777777777, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.5555555555555556, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.2777777777777778, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 1.8888888888888888, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.2777777777777777, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.1666666666666667, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.9444444444444444, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.6111111111111112, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.5555555555555554, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.7777777777777778, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.2222222222222223, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.05555555555555555, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 1, "potting_onion_agent_1_mean": 0.5555555555555556, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.8333333333333335, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.16666666666666666, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.1111111111111111, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.388888888888889, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.7222222222222223, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.2222222222222223, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.2222222222222222, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.1111111111111111, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.16666666666666666, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.05555555555555555, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.05555555555555555, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.05555555555555555, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.05555555555555555, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 1, "optimal_onion_potting_agent_1_mean": 0.5555555555555556, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.5, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.16666666666666666, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.05555555555555555, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 1, "viable_onion_potting_agent_1_mean": 0.5555555555555556, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5555555555555556, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.2222222222222222, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.05555555555555555, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.0007812500116415322, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34979644417762756, "policy_loss": -1.8632412093211315e-06, "vf_loss": 6.307437896728516, "vf_explained_var": -0.0002181529998779297, "kl": -5.1320298705137546e-11, "entropy": 1.7903201580047607, "entropy_coeff": 0.19573333859443665, "model": {}}}}, "num_env_steps_sampled": 7200, "num_env_steps_trained": 7200, "num_agent_steps_sampled": 14400, "num_agent_steps_trained": 14400}, "sampler_results": {"episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 32.79234288709581, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 15.577223017297444, "bc": 20.490913574800206}, "custom_metrics": {"sparse_reward_mean": 2.1666666666666665, "sparse_reward_min": 0, "sparse_reward_max": 26, "shaped_reward_mean": 6.833333333333333, "shaped_reward_min": 0, "shaped_reward_max": 22, "tomato_pickup_agent_0_mean": 1.0555555555555556, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.2222222222222223, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5555555555555556, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.4444444444444444, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.8333333333333333, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.4444444444444446, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8888888888888888, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.2777777777777777, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.5555555555555556, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.2777777777777778, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 1, "onion_pickup_agent_0_mean": 1.8888888888888888, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.2777777777777777, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.1666666666666667, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.9444444444444444, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.6111111111111112, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.5555555555555554, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.7777777777777778, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.2222222222222223, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.05555555555555555, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 1, "potting_onion_agent_1_mean": 0.5555555555555556, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.8333333333333335, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 2.0, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.16666666666666666, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 1, "useful_dish_pickup_agent_1_mean": 0.1111111111111111, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.388888888888889, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.7222222222222223, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.2222222222222223, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 1.0, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.2222222222222222, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.1111111111111111, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.16666666666666666, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.05555555555555555, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.05555555555555555, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.05555555555555555, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.05555555555555555, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 1, "optimal_onion_potting_agent_1_mean": 0.5555555555555556, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.5, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.16666666666666666, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 1, "viable_onion_potting_agent_0_mean": 0.05555555555555555, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 1, "viable_onion_potting_agent_1_mean": 0.5555555555555556, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5555555555555556, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.2222222222222222, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 1, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.0, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 0, "catastrophic_tomato_potting_agent_1_mean": 0.05555555555555555, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4135579175987917, "mean_inference_ms": 2.2591359469278367, "mean_action_processing_ms": 0.06651181816979496, "mean_env_wait_ms": 0.7647443103127523, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.17071671270779, "episode_reward_min": 0.0, "episode_reward_mean": 32.79234288709581, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 59.58535835635389, "bc": 59.58535835635389}, "policy_reward_mean": {"ppo": 15.577223017297444, "bc": 20.490913574800206}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4135579175987917, "mean_inference_ms": 2.2591359469278367, "mean_action_processing_ms": 0.06651181816979496, "mean_env_wait_ms": 0.7647443103127523, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 14400, "num_agent_steps_trained": 14400, "num_env_steps_sampled": 7200, "num_env_steps_trained": 7200, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 7200, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 14400, "timers": {"training_iteration_time_ms": 1731.771, "learn_time_ms": 66.655, "learn_throughput": 12002.124, "synch_weights_time_ms": 5.067}, "counters": {"num_env_steps_sampled": 7200, "num_env_steps_trained": 7200, "num_agent_steps_sampled": 14400, "num_agent_steps_trained": 14400}, "done": false, "episodes_total": 18, "training_iteration": 9, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-06", "timestamp": 1733745726, "time_this_iter_s": 2.2670881748199463, "time_total_s": 17.29865336418152, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 17.29865336418152, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 75.95}}
{"evaluation": {"average_sparse_reward": 0.0, "num_healthy_workers": 0, "num_recreated_workers": 0}, "custom_metrics": {"sparse_reward_mean": 3.25, "sparse_reward_min": 0, "sparse_reward_max": 26, "shaped_reward_mean": 8.7, "shaped_reward_min": 0, "shaped_reward_max": 34, "tomato_pickup_agent_0_mean": 1.0, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.25, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.45, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.75, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.6, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.9, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.25, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.6, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.4, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 2, "onion_pickup_agent_0_mean": 1.85, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.05, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.2, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.8, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.45, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.35, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.7, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.15, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.2, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.55, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.8, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.85, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.3, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.1, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.2, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.55, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.15, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.9, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.35, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.3, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.05, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.05, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.05, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.2, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.55, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.5, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.3, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 2, "viable_onion_potting_agent_0_mean": 0.2, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.55, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.55, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.35, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 2, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.05, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.05, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.0003906250058207661, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34862542152404785, "policy_loss": -5.865097136847908e-07, "vf_loss": 8.113966941833496, "vf_explained_var": -0.000461578369140625, "kl": 9.502750586420916e-09, "entropy": 1.790144681930542, "entropy_coeff": 0.19519999623298645, "model": {}}}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "sampler_results": {"episode_reward_max": 247.00467177754845, "episode_reward_min": 0.0, "episode_reward_mean": 47.82187802289904, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 123.50233588877423, "bc": 123.50233588877423}, "policy_reward_mean": {"ppo": 20.325137023876607, "bc": 38.25414696174117}, "custom_metrics": {"sparse_reward_mean": 3.25, "sparse_reward_min": 0, "sparse_reward_max": 26, "shaped_reward_mean": 8.7, "shaped_reward_min": 0, "shaped_reward_max": 34, "tomato_pickup_agent_0_mean": 1.0, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.25, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.45, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.75, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.6, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.9, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.25, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.6, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.4, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 2, "onion_pickup_agent_0_mean": 1.85, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 3.05, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.2, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.8, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.45, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.35, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.7, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.15, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.2, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.55, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.8, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.85, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.3, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.1, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.2, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.55, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.15, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.9, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.35, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.3, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.05, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.05, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.05, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.2, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.55, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.5, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.3, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 2, "viable_onion_potting_agent_0_mean": 0.2, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.55, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.55, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.35, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 2, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.05, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.05, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4122342022752935, "mean_inference_ms": 2.2993027274306757, "mean_action_processing_ms": 0.06884503618982214, "mean_env_wait_ms": 0.7802776320286922, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 247.00467177754845, "episode_reward_min": 0.0, "episode_reward_mean": 47.82187802289904, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 123.50233588877423, "bc": 123.50233588877423}, "policy_reward_mean": {"ppo": 20.325137023876607, "bc": 38.25414696174117}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4122342022752935, "mean_inference_ms": 2.2993027274306757, "mean_action_processing_ms": 0.06884503618982214, "mean_env_wait_ms": 0.7802776320286922, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 8000, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 1784.805, "learn_time_ms": 61.063, "learn_throughput": 13101.223, "synch_weights_time_ms": 4.761}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 20, "training_iteration": 10, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-10", "timestamp": 1733745730, "time_this_iter_s": 3.8532907962799072, "time_total_s": 21.151944160461426, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 21.151944160461426, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 25.199999999999996, "ram_util_percent": 75.9}}
{"custom_metrics": {"sparse_reward_mean": 6.5, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 9.363636363636363, "shaped_reward_min": 0, "shaped_reward_max": 34, "tomato_pickup_agent_0_mean": 1.1363636363636365, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.1363636363636362, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.45454545454545453, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.3181818181818181, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.0, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.3181818181818183, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.1363636363636365, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.1818181818181819, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.5909090909090909, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.6363636363636364, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.0454545454545454, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 2.909090909090909, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.3636363636363635, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.6818181818181819, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.6818181818181819, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.227272727272727, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.7727272727272727, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.1363636363636365, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.18181818181818182, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5454545454545454, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.590909090909091, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.6818181818181819, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.3181818181818182, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.09090909090909091, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.0, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.4090909090909092, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.0454545454545454, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.8181818181818182, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.4090909090909091, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.09090909090909091, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.3181818181818182, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.045454545454545456, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.09090909090909091, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.045454545454545456, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.18181818181818182, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5454545454545454, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.45454545454545453, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.18181818181818182, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5454545454545454, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5454545454545454, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.5909090909090909, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.045454545454545456, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.045454545454545456, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 0.00019531250291038305, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34809809923171997, "policy_loss": -6.282329536588804e-07, "vf_loss": 4.2943501472473145, "vf_explained_var": -0.00043594837188720703, "kl": 3.417979677067251e-09, "entropy": 1.7903779745101929, "entropy_coeff": 0.19466666877269745, "model": {}}}}, "num_env_steps_sampled": 8800, "num_env_steps_trained": 8800, "num_agent_steps_sampled": 17600, "num_agent_steps_trained": 17600}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 61.9477087819854, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 25.106188268732367, "bc": 50.92391920667784}, "custom_metrics": {"sparse_reward_mean": 6.5, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 9.363636363636363, "shaped_reward_min": 0, "shaped_reward_max": 34, "tomato_pickup_agent_0_mean": 1.1363636363636365, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.1363636363636362, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.45454545454545453, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.3181818181818181, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 2.0, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.3181818181818183, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.1363636363636365, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.1818181818181819, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.5909090909090909, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.6363636363636364, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.0454545454545454, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 7, "onion_pickup_agent_1_mean": 2.909090909090909, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.3636363636363635, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 5, "useful_onion_pickup_agent_1_mean": 1.6818181818181819, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.6818181818181819, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 6, "onion_drop_agent_1_mean": 2.227272727272727, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 0.7727272727272727, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 4, "useful_onion_drop_agent_1_mean": 1.1363636363636365, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.18181818181818182, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5454545454545454, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.590909090909091, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.6818181818181819, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.3181818181818182, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.09090909090909091, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 2.0, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.4090909090909092, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 1.0454545454545454, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.8181818181818182, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.4090909090909091, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.09090909090909091, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.3181818181818182, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.045454545454545456, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.09090909090909091, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.045454545454545456, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.18181818181818182, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5454545454545454, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.45454545454545453, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.18181818181818182, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5454545454545454, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5454545454545454, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.5909090909090909, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 0, "catastrophic_tomato_potting_agent_0_mean": 0.045454545454545456, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.045454545454545456, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4114418350858001, "mean_inference_ms": 2.3455039258201213, "mean_action_processing_ms": 0.07051132845592369, "mean_env_wait_ms": 0.7942369695010494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 61.9477087819854, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.8953382542587178}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 25.106188268732367, "bc": 50.92391920667784}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4114418350858001, "mean_inference_ms": 2.3455039258201213, "mean_action_processing_ms": 0.07051132845592369, "mean_env_wait_ms": 0.7942369695010494, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 17600, "num_agent_steps_trained": 17600, "num_env_steps_sampled": 8800, "num_env_steps_trained": 8800, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 8800, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 17600, "timers": {"training_iteration_time_ms": 1826.099, "learn_time_ms": 19.872, "learn_throughput": 40256.977, "synch_weights_time_ms": 2.122}, "counters": {"num_env_steps_sampled": 8800, "num_env_steps_trained": 8800, "num_agent_steps_sampled": 17600, "num_agent_steps_trained": 17600}, "done": false, "episodes_total": 22, "training_iteration": 11, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-12", "timestamp": 1733745732, "time_this_iter_s": 2.3700170516967773, "time_total_s": 23.521961212158203, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 23.521961212158203, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 27.275, "ram_util_percent": 75.9}}
{"custom_metrics": {"sparse_reward_mean": 5.958333333333333, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 9.333333333333334, "shaped_reward_min": 0, "shaped_reward_max": 34, "tomato_pickup_agent_0_mean": 1.1666666666666667, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.9583333333333333, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5416666666666666, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.2083333333333333, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.9583333333333333, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.0416666666666665, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0416666666666667, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.0833333333333333, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.625, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.7083333333333334, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.5416666666666665, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 2.75, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.5416666666666667, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 1.625, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.1666666666666665, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.0833333333333335, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 1.0833333333333333, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0833333333333333, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.16666666666666666, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5416666666666666, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.5, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.5416666666666667, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.2916666666666667, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.08333333333333333, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.9583333333333333, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.2916666666666667, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.9583333333333334, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.75, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.375, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.08333333333333333, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.2916666666666667, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.041666666666666664, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08333333333333333, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.041666666666666664, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.16666666666666666, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.4166666666666667, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.5833333333333334, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.16666666666666666, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5833333333333334, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.6666666666666666, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.041666666666666664, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.041666666666666664, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.041666666666666664, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 9.765625145519152e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34719908237457275, "policy_loss": 6.7889692445533e-07, "vf_loss": 4.131269931793213, "vf_explained_var": -0.001050710678100586, "kl": 1.841782060196806e-09, "entropy": 1.79058837890625, "entropy_coeff": 0.19413332641124725, "model": {}}}}, "num_env_steps_sampled": 9600, "num_env_steps_trained": 9600, "num_agent_steps_sampled": 19200, "num_agent_steps_trained": 19200}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 62.16995372266839, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 25.506251366863378, "bc": 47.82115334474664}, "custom_metrics": {"sparse_reward_mean": 5.958333333333333, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 9.333333333333334, "shaped_reward_min": 0, "shaped_reward_max": 34, "tomato_pickup_agent_0_mean": 1.1666666666666667, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.9583333333333333, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5416666666666666, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.2083333333333333, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.9583333333333333, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.0416666666666665, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0416666666666667, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.0833333333333333, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.625, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 3, "potting_tomato_agent_1_mean": 0.7083333333333334, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.5416666666666665, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 2.75, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.5416666666666667, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 1.625, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.1666666666666665, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.0833333333333335, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 7, "useful_onion_drop_agent_0_mean": 1.0833333333333333, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0833333333333333, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.16666666666666666, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5416666666666666, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.5, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.5416666666666667, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.2916666666666667, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.08333333333333333, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.9583333333333333, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.2916666666666667, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.9583333333333334, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.75, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.375, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 2, "soup_pickup_agent_1_mean": 0.08333333333333333, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.2916666666666667, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.041666666666666664, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08333333333333333, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.041666666666666664, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.16666666666666666, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.4166666666666667, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 2, "optimal_tomato_potting_agent_1_mean": 0.5833333333333334, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.16666666666666666, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.5833333333333334, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 3, "viable_tomato_potting_agent_1_mean": 0.6666666666666666, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.041666666666666664, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.041666666666666664, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.041666666666666664, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4106938700073111, "mean_inference_ms": 2.3919447548638866, "mean_action_processing_ms": 0.0718520779282212, "mean_env_wait_ms": 0.8077197942343558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 62.16995372266839, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 25.506251366863378, "bc": 47.82115334474664}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4106938700073111, "mean_inference_ms": 2.3919447548638866, "mean_action_processing_ms": 0.0718520779282212, "mean_env_wait_ms": 0.8077197942343558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 19200, "num_agent_steps_trained": 19200, "num_env_steps_sampled": 9600, "num_env_steps_trained": 9600, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 9600, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 19200, "timers": {"training_iteration_time_ms": 1932.081, "learn_time_ms": 18.083, "learn_throughput": 44239.688, "synch_weights_time_ms": 1.813}, "counters": {"num_env_steps_sampled": 9600, "num_env_steps_trained": 9600, "num_agent_steps_sampled": 19200, "num_agent_steps_trained": 19200}, "done": false, "episodes_total": 24, "training_iteration": 12, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-15", "timestamp": 1733745735, "time_this_iter_s": 2.2943472862243652, "time_total_s": 25.81630849838257, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 25.81630849838257, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 29.133333333333336, "ram_util_percent": 75.9}}
{"custom_metrics": {"sparse_reward_mean": 9.5, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 10.884615384615385, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 1.0769230769230769, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.0, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.2307692307692308, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.8846153846153846, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.076923076923077, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0384615384615385, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.1153846153846154, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.8846153846153846, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 4, "potting_tomato_agent_1_mean": 0.6538461538461539, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.3461538461538463, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 2.923076923076923, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.4230769230769231, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 1.8076923076923077, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.0, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.269230769230769, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 8, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.15384615384615385, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.5, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.4230769230769231, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.46153846153846156, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.07692307692307693, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.8076923076923077, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.1923076923076923, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.8846153846153846, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.6923076923076923, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.07692307692307693, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.38461538461538464, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.038461538461538464, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.11538461538461539, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.038461538461538464, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.15384615384615385, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.46153846153846156, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.6153846153846154, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5384615384615384, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.15384615384615385, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.46153846153846156, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.8461538461538461, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 4, "viable_tomato_potting_agent_1_mean": 0.6153846153846154, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.038461538461538464, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.038461538461538464, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.038461538461538464, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 4.882812572759576e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.345920205116272, "policy_loss": -6.318092005130893e-08, "vf_loss": 7.123522758483887, "vf_explained_var": -0.0005785226821899414, "kl": -3.433676606934277e-11, "entropy": 1.7904571294784546, "entropy_coeff": 0.19359999895095825, "model": {}}}}, "num_env_steps_sampled": 10400, "num_env_steps_trained": 10400, "num_agent_steps_sampled": 20800, "num_agent_steps_trained": 20800}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 70.95470267837833, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 28.805177351420507, "bc": 53.58753787741838}, "custom_metrics": {"sparse_reward_mean": 9.5, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 10.884615384615385, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 1.0769230769230769, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 2.0, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.2307692307692308, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.8846153846153846, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 3.076923076923077, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0384615384615385, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.1153846153846154, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.8846153846153846, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 4, "potting_tomato_agent_1_mean": 0.6538461538461539, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.3461538461538463, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 2.923076923076923, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 9, "useful_onion_pickup_agent_0_mean": 1.4230769230769231, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 1.8076923076923077, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.0, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.269230769230769, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 8, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.15384615384615385, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.5, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.4230769230769231, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.46153846153846156, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.07692307692307693, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.8076923076923077, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.1923076923076923, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.8846153846153846, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.6923076923076923, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.07692307692307693, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.38461538461538464, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.038461538461538464, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.11538461538461539, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.038461538461538464, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.15384615384615385, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.46153846153846156, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.6153846153846154, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5384615384615384, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.15384615384615385, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.46153846153846156, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.8461538461538461, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 4, "viable_tomato_potting_agent_1_mean": 0.6153846153846154, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.038461538461538464, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.038461538461538464, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.038461538461538464, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4100874713699602, "mean_inference_ms": 2.4372849545983897, "mean_action_processing_ms": 0.07315503688992017, "mean_env_wait_ms": 0.8209183213230034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 70.95470267837833, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 28.805177351420507, "bc": 53.58753787741838}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4100874713699602, "mean_inference_ms": 2.4372849545983897, "mean_action_processing_ms": 0.07315503688992017, "mean_env_wait_ms": 0.8209183213230034, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 20800, "num_agent_steps_trained": 20800, "num_env_steps_sampled": 10400, "num_env_steps_trained": 10400, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 10400, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 20800, "timers": {"training_iteration_time_ms": 2037.391, "learn_time_ms": 15.667, "learn_throughput": 51061.314, "synch_weights_time_ms": 1.513}, "counters": {"num_env_steps_sampled": 10400, "num_env_steps_trained": 10400, "num_agent_steps_sampled": 20800, "num_agent_steps_trained": 20800}, "done": false, "episodes_total": 26, "training_iteration": 13, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-17", "timestamp": 1733745737, "time_this_iter_s": 2.3207075595855713, "time_total_s": 28.13701605796814, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 28.13701605796814, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 28.066666666666666, "ram_util_percent": 75.9}}
{"custom_metrics": {"sparse_reward_mean": 14.392857142857142, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 11.642857142857142, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 1.0357142857142858, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.8571428571428572, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.1428571428571428, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.7857142857142858, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.892857142857143, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.0714285714285714, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.9642857142857143, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 4, "potting_tomato_agent_1_mean": 0.7142857142857143, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.392857142857143, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.1785714285714284, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 10, "useful_onion_pickup_agent_0_mean": 1.4285714285714286, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.0, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.0714285714285716, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.4285714285714284, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 8, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0357142857142858, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.14285714285714285, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5357142857142857, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.4285714285714284, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.4285714285714286, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.4642857142857143, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.10714285714285714, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.7142857142857142, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.1785714285714286, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.8214285714285714, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.6428571428571429, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.10714285714285714, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.39285714285714285, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.07142857142857142, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.10714285714285714, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.03571428571428571, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.14285714285714285, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.6785714285714286, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5714285714285714, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.14285714285714285, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.9285714285714286, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 4, "viable_tomato_potting_agent_1_mean": 0.6785714285714286, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.03571428571428571, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.03571428571428571, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.03571428571428571, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 2.441406286379788e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34507355093955994, "policy_loss": 3.6835669448009867e-07, "vf_loss": 6.144901752471924, "vf_explained_var": 6.473064422607422e-05, "kl": 6.383676698362706e-09, "entropy": 1.7905131578445435, "entropy_coeff": 0.19306667149066925, "model": {}}}}, "num_env_steps_sampled": 11200, "num_env_steps_trained": 11200, "num_agent_steps_sampled": 22400, "num_agent_steps_trained": 22400}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 77.1498419692346, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 31.307084802608635, "bc": 56.744511439638956}, "custom_metrics": {"sparse_reward_mean": 14.392857142857142, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 11.642857142857142, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 1.0357142857142858, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.8571428571428572, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.5, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.1428571428571428, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.7857142857142858, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.892857142857143, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 1.0, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.0714285714285714, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 0.9642857142857143, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 4, "potting_tomato_agent_1_mean": 0.7142857142857143, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.392857142857143, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.1785714285714284, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 10, "useful_onion_pickup_agent_0_mean": 1.4285714285714286, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.0, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 2.0714285714285716, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.4285714285714284, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 8, "useful_onion_drop_agent_0_mean": 1.0, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0357142857142858, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.14285714285714285, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5357142857142857, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.4285714285714284, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.4285714285714286, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.4642857142857143, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.10714285714285714, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.7142857142857142, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.1785714285714286, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.8214285714285714, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.6428571428571429, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.10714285714285714, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.39285714285714285, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.07142857142857142, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.10714285714285714, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.03571428571428571, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.14285714285714285, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.6785714285714286, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5714285714285714, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.14285714285714285, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.9285714285714286, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 4, "viable_tomato_potting_agent_1_mean": 0.6785714285714286, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.03571428571428571, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.03571428571428571, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.03571428571428571, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4098596366492541, "mean_inference_ms": 2.4800191655839554, "mean_action_processing_ms": 0.07423666703469305, "mean_env_wait_ms": 0.8330244560515129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 77.1498419692346, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 31.307084802608635, "bc": 56.744511439638956}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4098596366492541, "mean_inference_ms": 2.4800191655839554, "mean_action_processing_ms": 0.07423666703469305, "mean_env_wait_ms": 0.8330244560515129, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 22400, "num_agent_steps_trained": 22400, "num_env_steps_sampled": 11200, "num_env_steps_trained": 11200, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 11200, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 22400, "timers": {"training_iteration_time_ms": 2057.248, "learn_time_ms": 11.739, "learn_throughput": 68146.324, "synch_weights_time_ms": 1.413}, "counters": {"num_env_steps_sampled": 11200, "num_env_steps_trained": 11200, "num_agent_steps_sampled": 22400, "num_agent_steps_trained": 22400}, "done": false, "episodes_total": 28, "training_iteration": 14, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-19", "timestamp": 1733745739, "time_this_iter_s": 2.2111284732818604, "time_total_s": 30.34814453125, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 30.34814453125, "timesteps_since_restore": 0, "iterations_since_restore": 14, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 28.625, "ram_util_percent": 75.9}}
{"evaluation": {"average_sparse_reward": 13.0, "num_healthy_workers": 0, "num_recreated_workers": 0}, "custom_metrics": {"sparse_reward_mean": 13.433333333333334, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 11.566666666666666, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.9666666666666667, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.8, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4666666666666667, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.0666666666666667, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.7, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.9, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.9333333333333333, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.1666666666666667, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.0333333333333334, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 4, "potting_tomato_agent_1_mean": 0.6666666666666666, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.2333333333333334, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.1, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 10, "useful_onion_pickup_agent_0_mean": 1.3333333333333333, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 1.9333333333333333, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.9333333333333333, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.3666666666666667, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 8, "useful_onion_drop_agent_0_mean": 0.9333333333333333, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0666666666666667, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.13333333333333333, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5333333333333333, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.2666666666666666, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.4666666666666666, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.43333333333333335, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.16666666666666666, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.6, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.2333333333333334, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.7666666666666667, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.6, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.4666666666666667, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.36666666666666664, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.06666666666666667, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.1, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.03333333333333333, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.13333333333333333, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.7, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5333333333333333, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.13333333333333333, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.9666666666666667, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 4, "viable_tomato_potting_agent_1_mean": 0.6333333333333333, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.03333333333333333, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.06666666666666667, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.03333333333333333, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 1.220703143189894e-05, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34443843364715576, "policy_loss": 5.3048132997446373e-08, "vf_loss": 2.309079647064209, "vf_explained_var": -0.0004266500473022461, "kl": -3.4566951523373746e-09, "entropy": 1.7901805639266968, "entropy_coeff": 0.19253332912921906, "model": {}}}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 72.11557342963192, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.855219189989043, "bc": 50.53044427274543}, "custom_metrics": {"sparse_reward_mean": 13.433333333333334, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 11.566666666666666, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.9666666666666667, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.8, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4666666666666667, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.0666666666666667, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.7, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.9, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.9333333333333333, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.1666666666666667, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.0333333333333334, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 4, "potting_tomato_agent_1_mean": 0.6666666666666666, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.2333333333333334, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.1, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 10, "useful_onion_pickup_agent_0_mean": 1.3333333333333333, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 1.9333333333333333, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 9, "onion_drop_agent_0_mean": 1.9333333333333333, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.3666666666666667, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 8, "useful_onion_drop_agent_0_mean": 0.9333333333333333, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0666666666666667, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.13333333333333333, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5333333333333333, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.2666666666666666, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.4666666666666666, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.43333333333333335, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.16666666666666666, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.6, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.2333333333333334, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.7666666666666667, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.6, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.4666666666666667, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.36666666666666664, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.06666666666666667, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.1, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.03333333333333333, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.13333333333333333, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.7, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5333333333333333, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.13333333333333333, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 0.9666666666666667, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 4, "viable_tomato_potting_agent_1_mean": 0.6333333333333333, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.03333333333333333, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.06666666666666667, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.03333333333333333, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4096555047449076, "mean_inference_ms": 2.521459541243104, "mean_action_processing_ms": 0.07524763897042705, "mean_env_wait_ms": 0.8442621149260783, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 72.11557342963192, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.855219189989043, "bc": 50.53044427274543}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4096555047449076, "mean_inference_ms": 2.521459541243104, "mean_action_processing_ms": 0.07524763897042705, "mean_env_wait_ms": 0.8442621149260783, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 12000, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 24000, "timers": {"training_iteration_time_ms": 2160.085, "learn_time_ms": 11.789, "learn_throughput": 67858.154, "synch_weights_time_ms": 1.457}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 30, "training_iteration": 15, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-23", "timestamp": 1733745743, "time_this_iter_s": 3.9820873737335205, "time_total_s": 34.33023190498352, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 34.33023190498352, "timesteps_since_restore": 0, "iterations_since_restore": 15, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 25.02, "ram_util_percent": 75.9}}
{"custom_metrics": {"sparse_reward_mean": 13.0, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 12.09375, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.9375, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.71875, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.46875, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.03125, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.65625, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.78125, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.875, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.09375, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.125, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.625, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.15625, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.3125, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.3125, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.15625, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.84375, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.5625, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.875, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.03125, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.15625, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5625, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.3125, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.40625, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.46875, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.15625, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.625, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.15625, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.84375, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.5625, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.09375, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.40625, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.0625, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.09375, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.03125, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.15625, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.75, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.15625, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 1.0625, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.59375, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0625, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.0625, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.03125, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 6.10351571594947e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -0.34320294857025146, "policy_loss": 2.384185791015625e-07, "vf_loss": 5.7297492027282715, "vf_explained_var": -0.000716090202331543, "kl": 6.832684196211858e-09, "entropy": 1.790500521659851, "entropy_coeff": 0.19200000166893005, "model": {}}}}, "num_env_steps_sampled": 12800, "num_env_steps_trained": 12800, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 25600}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 72.63138598545032, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 30.32472227959695, "bc": 49.49582856160719}, "custom_metrics": {"sparse_reward_mean": 13.0, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 12.09375, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.9375, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.71875, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.46875, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.03125, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.65625, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.78125, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.875, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.09375, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.125, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.625, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.15625, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.3125, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.3125, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.15625, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.84375, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.5625, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.875, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.03125, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.15625, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5625, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.3125, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.40625, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.46875, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.15625, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.625, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.15625, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.84375, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.5625, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.09375, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.40625, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.0625, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.09375, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.03125, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.15625, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.5, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.75, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.15625, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.5, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 1.0625, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.59375, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.0625, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.0625, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.03125, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4100259015151194, "mean_inference_ms": 2.5610604411211595, "mean_action_processing_ms": 0.07604938816273188, "mean_env_wait_ms": 0.8549373497038957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 72.63138598545032, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 30.32472227959695, "bc": 49.49582856160719}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4100259015151194, "mean_inference_ms": 2.5610604411211595, "mean_action_processing_ms": 0.07604938816273188, "mean_env_wait_ms": 0.8549373497038957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 25600, "num_env_steps_sampled": 12800, "num_env_steps_trained": 12800, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 12800, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 25600, "timers": {"training_iteration_time_ms": 2182.413, "learn_time_ms": 10.673, "learn_throughput": 74956.846, "synch_weights_time_ms": 1.101}, "counters": {"num_env_steps_sampled": 12800, "num_env_steps_trained": 12800, "num_agent_steps_sampled": 25600, "num_agent_steps_trained": 25600}, "done": false, "episodes_total": 32, "training_iteration": 16, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-26", "timestamp": 1733745746, "time_this_iter_s": 2.358907461166382, "time_total_s": 36.6891393661499, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 36.6891393661499, "timesteps_since_restore": 0, "iterations_since_restore": 16, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 25.6, "ram_util_percent": 75.92500000000001}}
{"custom_metrics": {"sparse_reward_mean": 12.617647058823529, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 12.147058823529411, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.8823529411764706, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.6764705882352942, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4411764705882353, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.0294117647058822, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.5588235294117647, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.7058823529411766, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8235294117647058, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.0294117647058822, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.088235294117647, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.6470588235294118, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.0588235294117645, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.4411764705882355, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.2647058823529411, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.3529411764705883, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.7352941176470589, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.7058823529411766, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.8235294117647058, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.17647058823529413, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5588235294117647, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.264705882352941, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.3235294117647058, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.5, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.14705882352941177, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.588235294117647, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.088235294117647, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.8235294117647058, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.5294117647058824, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.08823529411764706, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.4117647058823529, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.058823529411764705, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08823529411764706, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.029411764705882353, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.17647058823529413, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.47058823529411764, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.7352941176470589, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.17647058823529413, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.47058823529411764, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 1.0294117647058822, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.6176470588235294, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.08823529411764706, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.058823529411764705, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.029411764705882353, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 3.051757857974735e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -0.3422451317310333, "policy_loss": 2.8610228852699038e-08, "vf_loss": 5.8445658683776855, "vf_explained_var": -0.000826716423034668, "kl": 2.6045878787073207e-09, "entropy": 1.7905446290969849, "entropy_coeff": 0.19146665930747986, "model": {}}}}, "num_env_steps_sampled": 13600, "num_env_steps_trained": 13600, "num_agent_steps_sampled": 27200, "num_agent_steps_trained": 27200}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 69.21988174367056, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.32442596037957, "bc": 45.66147205033356}, "custom_metrics": {"sparse_reward_mean": 12.617647058823529, "sparse_reward_min": 0, "sparse_reward_max": 78, "shaped_reward_mean": 12.147058823529411, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.8823529411764706, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.6764705882352942, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4411764705882353, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.0294117647058822, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.5588235294117647, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.7058823529411766, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8235294117647058, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 1.0294117647058822, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.088235294117647, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.6470588235294118, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.0588235294117645, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.4411764705882355, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.2647058823529411, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.3529411764705883, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.7352941176470589, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.7058823529411766, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.8235294117647058, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 1.0, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.17647058823529413, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5588235294117647, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.264705882352941, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.3235294117647058, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.5, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.14705882352941177, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.588235294117647, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.088235294117647, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.8235294117647058, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.5294117647058824, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.08823529411764706, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.4117647058823529, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.058823529411764705, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08823529411764706, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.029411764705882353, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.17647058823529413, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.47058823529411764, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.7352941176470589, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.17647058823529413, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.47058823529411764, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 1.0294117647058822, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.6176470588235294, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.08823529411764706, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.058823529411764705, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.029411764705882353, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41017562828935455, "mean_inference_ms": 2.5983794279515604, "mean_action_processing_ms": 0.07691373898860816, "mean_env_wait_ms": 0.8649991780318462, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 69.21988174367056, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.32442596037957, "bc": 45.66147205033356}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.41017562828935455, "mean_inference_ms": 2.5983794279515604, "mean_action_processing_ms": 0.07691373898860816, "mean_env_wait_ms": 0.8649991780318462, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 27200, "num_agent_steps_trained": 27200, "num_env_steps_sampled": 13600, "num_env_steps_trained": 13600, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 13600, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 27200, "timers": {"training_iteration_time_ms": 2274.523, "learn_time_ms": 8.628, "learn_throughput": 92723.05, "synch_weights_time_ms": 0.801}, "counters": {"num_env_steps_sampled": 13600, "num_env_steps_trained": 13600, "num_agent_steps_sampled": 27200, "num_agent_steps_trained": 27200}, "done": false, "episodes_total": 34, "training_iteration": 17, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-28", "timestamp": 1733745748, "time_this_iter_s": 2.276660442352295, "time_total_s": 38.9657998085022, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 38.9657998085022, "timesteps_since_restore": 0, "iterations_since_restore": 17, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 27.96666666666667, "ram_util_percent": 76.0}}
{"custom_metrics": {"sparse_reward_mean": 14.444444444444445, "sparse_reward_min": 0, "sparse_reward_max": 91, "shaped_reward_mean": 12.416666666666666, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.9166666666666666, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.6111111111111112, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4722222222222222, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.0, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.6111111111111112, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.5833333333333335, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8611111111111112, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 0.9722222222222222, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.1388888888888888, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.6666666666666666, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.0, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.4166666666666665, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.1944444444444444, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.361111111111111, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.6944444444444444, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.7222222222222223, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.8333333333333334, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 0.9444444444444444, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.16666666666666666, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5277777777777778, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.1944444444444446, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.25, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.5277777777777778, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.1388888888888889, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.5, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.0277777777777777, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.7777777777777778, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.5, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5277777777777778, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.08333333333333333, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.4444444444444444, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.05555555555555555, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08333333333333333, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.027777777777777776, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.16666666666666666, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.4444444444444444, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.75, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5277777777777778, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.16666666666666666, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.4444444444444444, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 1.0833333333333333, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.6388888888888888, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.08333333333333333, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.05555555555555555, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.027777777777777776, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 1.5258789289873675e-06, "cur_lr": 4.999999873689376e-05, "total_loss": -0.3413374423980713, "policy_loss": -4.6491624061673065e-07, "vf_loss": 5.8039727210998535, "vf_explained_var": -8.440017700195312e-05, "kl": 2.2514994313382886e-09, "entropy": 1.7907683849334717, "entropy_coeff": 0.19093333184719086, "model": {}}}}, "num_env_steps_sampled": 14400, "num_env_steps_trained": 14400, "num_agent_steps_sampled": 28800, "num_agent_steps_trained": 28800}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 70.4753275877776, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 30.01544793989704, "bc": 45.68209550187232}, "custom_metrics": {"sparse_reward_mean": 14.444444444444445, "sparse_reward_min": 0, "sparse_reward_max": 91, "shaped_reward_mean": 12.416666666666666, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.9166666666666666, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.6111111111111112, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4722222222222222, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 1.0, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.6111111111111112, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.5833333333333335, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8611111111111112, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 0.9722222222222222, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.1388888888888888, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.6666666666666666, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.0, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.4166666666666665, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.1944444444444444, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.361111111111111, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.6944444444444444, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.7222222222222223, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.8333333333333334, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 0.9444444444444444, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.16666666666666666, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5277777777777778, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 1, "dish_pickup_agent_0_mean": 2.1944444444444446, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.25, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.5277777777777778, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.1388888888888889, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.5, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.0277777777777777, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.7777777777777778, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.5, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5277777777777778, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.08333333333333333, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.4444444444444444, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.05555555555555555, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.08333333333333333, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.027777777777777776, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.16666666666666666, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.4444444444444444, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 1, "optimal_tomato_potting_agent_0_mean": 0.75, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5277777777777778, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.16666666666666666, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.4444444444444444, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 1, "viable_tomato_potting_agent_0_mean": 1.0833333333333333, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.6388888888888888, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.08333333333333333, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.05555555555555555, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.027777777777777776, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458, 1.635813875194458, 182.0], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4104558671367593, "mean_inference_ms": 2.6331014936853325, "mean_action_processing_ms": 0.0777237175568301, "mean_env_wait_ms": 0.8747088737927168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 70.4753275877776, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.817906937597229}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 30.01544793989704, "bc": 45.68209550187232}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458, 1.635813875194458, 182.0], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4104558671367593, "mean_inference_ms": 2.6331014936853325, "mean_action_processing_ms": 0.0777237175568301, "mean_env_wait_ms": 0.8747088737927168, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 28800, "num_agent_steps_trained": 28800, "num_env_steps_sampled": 14400, "num_env_steps_trained": 14400, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 14400, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 28800, "timers": {"training_iteration_time_ms": 2278.163, "learn_time_ms": 7.824, "learn_throughput": 102246.169, "synch_weights_time_ms": 0.801}, "counters": {"num_env_steps_sampled": 14400, "num_env_steps_trained": 14400, "num_agent_steps_sampled": 28800, "num_agent_steps_trained": 28800}, "done": false, "episodes_total": 36, "training_iteration": 18, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-30", "timestamp": 1733745750, "time_this_iter_s": 2.2432875633239746, "time_total_s": 41.20908737182617, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 41.20908737182617, "timesteps_since_restore": 0, "iterations_since_restore": 18, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 26.166666666666668, "ram_util_percent": 76.0}}
{"custom_metrics": {"sparse_reward_mean": 14.368421052631579, "sparse_reward_min": 0, "sparse_reward_max": 91, "shaped_reward_mean": 12.868421052631579, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.868421052631579, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.5263157894736843, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4473684210526316, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 0.9473684210526315, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.5526315789473684, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.5, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8421052631578947, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 0.9736842105263158, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.131578947368421, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.6578947368421053, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.1315789473684212, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.3684210526315788, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.236842105263158, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.289473684210526, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.8157894736842106, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.6315789473684212, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.9210526315789473, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 0.9473684210526315, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.18421052631578946, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5526315789473685, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 2, "dish_pickup_agent_0_mean": 2.210526315789474, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.2894736842105263, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.5263157894736842, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.18421052631578946, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.4736842105263157, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.0526315789473684, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.7631578947368421, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.47368421052631576, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5526315789473685, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.10526315789473684, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.47368421052631576, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.07894736842105263, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.07894736842105263, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.02631578947368421, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.18421052631578946, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.47368421052631576, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 2, "optimal_tomato_potting_agent_0_mean": 0.7631578947368421, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5263157894736842, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.18421052631578946, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.47368421052631576, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 2, "viable_tomato_potting_agent_0_mean": 1.0789473684210527, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.631578947368421, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.07894736842105263, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.05263157894736842, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.02631578947368421, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 7.629394644936838e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.340411901473999, "policy_loss": -5.793571631329542e-07, "vf_loss": 5.009964942932129, "vf_explained_var": -0.0004885196685791016, "kl": -4.836925970863604e-09, "entropy": 1.7905060052871704, "entropy_coeff": 0.19040000438690186, "model": {}}}}, "num_env_steps_sampled": 15200, "num_env_steps_trained": 15200, "num_agent_steps_sampled": 30400, "num_agent_steps_trained": 30400}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 68.17756860618915, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.0}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.351188161053102, "bc": 43.1995461147128}, "custom_metrics": {"sparse_reward_mean": 14.368421052631579, "sparse_reward_min": 0, "sparse_reward_max": 91, "shaped_reward_mean": 12.868421052631579, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.868421052631579, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.5263157894736843, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.4473684210526316, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 0.9473684210526315, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.5526315789473684, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.5, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.8421052631578947, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 0.9736842105263158, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.131578947368421, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.6578947368421053, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.1315789473684212, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.3684210526315788, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.236842105263158, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.289473684210526, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.8157894736842106, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.6315789473684212, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 0.9210526315789473, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 5, "useful_onion_drop_agent_1_mean": 0.9473684210526315, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.18421052631578946, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.5526315789473685, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 2, "dish_pickup_agent_0_mean": 2.210526315789474, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.2894736842105263, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 5, "useful_dish_pickup_agent_0_mean": 0.5263157894736842, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.18421052631578946, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.4736842105263157, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.0526315789473684, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 4, "useful_dish_drop_agent_0_mean": 0.7631578947368421, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.47368421052631576, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 4, "soup_pickup_agent_0_mean": 0.5526315789473685, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.10526315789473684, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.47368421052631576, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.07894736842105263, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.07894736842105263, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.02631578947368421, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.18421052631578946, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.47368421052631576, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 2, "optimal_tomato_potting_agent_0_mean": 0.7631578947368421, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5263157894736842, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.18421052631578946, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.47368421052631576, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 2, "viable_tomato_potting_agent_0_mean": 1.0789473684210527, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.631578947368421, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.07894736842105263, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.05263157894736842, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.02631578947368421, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458, 1.635813875194458, 182.0, 0.0, 53.63581387519446], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4108362641449943, "mean_inference_ms": 2.665409078636519, "mean_action_processing_ms": 0.07851148587566428, "mean_env_wait_ms": 0.8840220492916203, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 68.17756860618915, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.0}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.351188161053102, "bc": 43.1995461147128}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458, 1.635813875194458, 182.0, 0.0, 53.63581387519446], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4108362641449943, "mean_inference_ms": 2.665409078636519, "mean_action_processing_ms": 0.07851148587566428, "mean_env_wait_ms": 0.8840220492916203, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 30400, "num_agent_steps_trained": 30400, "num_env_steps_sampled": 15200, "num_env_steps_trained": 15200, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 15200, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 30400, "timers": {"training_iteration_time_ms": 2279.865, "learn_time_ms": 9.347, "learn_throughput": 85587.124, "synch_weights_time_ms": 0.935}, "counters": {"num_env_steps_sampled": 15200, "num_env_steps_trained": 15200, "num_agent_steps_sampled": 30400, "num_agent_steps_trained": 30400}, "done": false, "episodes_total": 38, "training_iteration": 19, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-33", "timestamp": 1733745753, "time_this_iter_s": 2.2846150398254395, "time_total_s": 43.49370241165161, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 43.49370241165161, "timesteps_since_restore": 0, "iterations_since_restore": 19, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 28.200000000000003, "ram_util_percent": 76.0}}
{"evaluation": {"average_sparse_reward": 0.0, "num_healthy_workers": 0, "num_recreated_workers": 0}, "custom_metrics": {"sparse_reward_mean": 13.65, "sparse_reward_min": 0, "sparse_reward_max": 91, "shaped_reward_mean": 12.575, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.85, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.475, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.425, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 0.925, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.575, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.425, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.875, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 0.925, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.1, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.625, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.2, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.325, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.225, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.225, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.9, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.575, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 1.025, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 6, "useful_onion_drop_agent_1_mean": 0.975, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.175, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.55, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 2, "dish_pickup_agent_0_mean": 2.2, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.45, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 9, "useful_dish_pickup_agent_0_mean": 0.525, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.175, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.475, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.225, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 9, "useful_dish_drop_agent_0_mean": 0.75, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.675, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 9, "soup_pickup_agent_0_mean": 0.55, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.45, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.075, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.075, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.025, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.175, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.475, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 2, "optimal_tomato_potting_agent_0_mean": 0.75, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.175, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.475, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 2, "viable_tomato_potting_agent_0_mean": 1.05, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.6, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.075, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.05, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.025, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "episode_media": {}, "num_recreated_workers": 0, "info": {"learner": {"ppo": {"learner_stats": {"cur_kl_coeff": 3.814697322468419e-07, "cur_lr": 4.999999873689376e-05, "total_loss": -0.33984461426734924, "policy_loss": -2.2649764730431343e-07, "vf_loss": 1.89078950881958, "vf_explained_var": -0.00010335445404052734, "kl": 3.538882076270511e-09, "entropy": 1.7909066677093506, "entropy_coeff": 0.18986666202545166, "model": {}}}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "sampler_results": {"episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 68.42640706452941, "episode_len_mean": 400.0, "episode_media": {}, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.0}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.629110496647108, "bc": 42.726519169840266}, "custom_metrics": {"sparse_reward_mean": 13.65, "sparse_reward_min": 0, "sparse_reward_max": 91, "shaped_reward_mean": 12.575, "shaped_reward_min": 0, "shaped_reward_max": 36, "tomato_pickup_agent_0_mean": 0.85, "tomato_pickup_agent_0_min": 0, "tomato_pickup_agent_0_max": 4, "tomato_pickup_agent_1_mean": 1.475, "tomato_pickup_agent_1_min": 0, "tomato_pickup_agent_1_max": 4, "useful_tomato_pickup_agent_0_mean": 0.425, "useful_tomato_pickup_agent_0_min": 0, "useful_tomato_pickup_agent_0_max": 3, "useful_tomato_pickup_agent_1_mean": 0.925, "useful_tomato_pickup_agent_1_min": 0, "useful_tomato_pickup_agent_1_max": 4, "tomato_drop_agent_0_mean": 1.575, "tomato_drop_agent_0_min": 0, "tomato_drop_agent_0_max": 5, "tomato_drop_agent_1_mean": 2.425, "tomato_drop_agent_1_min": 0, "tomato_drop_agent_1_max": 6, "useful_tomato_drop_agent_0_mean": 0.875, "useful_tomato_drop_agent_0_min": 0, "useful_tomato_drop_agent_0_max": 4, "useful_tomato_drop_agent_1_mean": 0.925, "useful_tomato_drop_agent_1_min": 0, "useful_tomato_drop_agent_1_max": 5, "potting_tomato_agent_0_mean": 1.1, "potting_tomato_agent_0_min": 0, "potting_tomato_agent_0_max": 5, "potting_tomato_agent_1_mean": 0.625, "potting_tomato_agent_1_min": 0, "potting_tomato_agent_1_max": 3, "onion_pickup_agent_0_mean": 2.2, "onion_pickup_agent_0_min": 0, "onion_pickup_agent_0_max": 10, "onion_pickup_agent_1_mean": 3.325, "onion_pickup_agent_1_min": 0, "onion_pickup_agent_1_max": 12, "useful_onion_pickup_agent_0_mean": 1.225, "useful_onion_pickup_agent_0_min": 0, "useful_onion_pickup_agent_0_max": 6, "useful_onion_pickup_agent_1_mean": 2.225, "useful_onion_pickup_agent_1_min": 0, "useful_onion_pickup_agent_1_max": 10, "onion_drop_agent_0_mean": 1.9, "onion_drop_agent_0_min": 0, "onion_drop_agent_0_max": 10, "onion_drop_agent_1_mean": 2.575, "onion_drop_agent_1_min": 0, "onion_drop_agent_1_max": 11, "useful_onion_drop_agent_0_mean": 1.025, "useful_onion_drop_agent_0_min": 0, "useful_onion_drop_agent_0_max": 6, "useful_onion_drop_agent_1_mean": 0.975, "useful_onion_drop_agent_1_min": 0, "useful_onion_drop_agent_1_max": 6, "potting_onion_agent_0_mean": 0.175, "potting_onion_agent_0_min": 0, "potting_onion_agent_0_max": 2, "potting_onion_agent_1_mean": 0.55, "potting_onion_agent_1_min": 0, "potting_onion_agent_1_max": 2, "dish_pickup_agent_0_mean": 2.2, "dish_pickup_agent_0_min": 0, "dish_pickup_agent_0_max": 9, "dish_pickup_agent_1_mean": 1.45, "dish_pickup_agent_1_min": 0, "dish_pickup_agent_1_max": 9, "useful_dish_pickup_agent_0_mean": 0.525, "useful_dish_pickup_agent_0_min": 0, "useful_dish_pickup_agent_0_max": 3, "useful_dish_pickup_agent_1_mean": 0.175, "useful_dish_pickup_agent_1_min": 0, "useful_dish_pickup_agent_1_max": 1, "dish_drop_agent_0_mean": 1.475, "dish_drop_agent_0_min": 0, "dish_drop_agent_0_max": 9, "dish_drop_agent_1_mean": 1.225, "dish_drop_agent_1_min": 0, "dish_drop_agent_1_max": 9, "useful_dish_drop_agent_0_mean": 0.75, "useful_dish_drop_agent_0_min": 0, "useful_dish_drop_agent_0_max": 6, "useful_dish_drop_agent_1_mean": 0.675, "useful_dish_drop_agent_1_min": 0, "useful_dish_drop_agent_1_max": 9, "soup_pickup_agent_0_mean": 0.55, "soup_pickup_agent_0_min": 0, "soup_pickup_agent_0_max": 3, "soup_pickup_agent_1_mean": 0.1, "soup_pickup_agent_1_min": 0, "soup_pickup_agent_1_max": 1, "soup_delivery_agent_0_mean": 0.45, "soup_delivery_agent_0_min": 0, "soup_delivery_agent_0_max": 2, "soup_delivery_agent_1_mean": 0.075, "soup_delivery_agent_1_min": 0, "soup_delivery_agent_1_max": 1, "soup_drop_agent_0_mean": 0.075, "soup_drop_agent_0_min": 0, "soup_drop_agent_0_max": 1, "soup_drop_agent_1_mean": 0.025, "soup_drop_agent_1_min": 0, "soup_drop_agent_1_max": 1, "optimal_onion_potting_agent_0_mean": 0.175, "optimal_onion_potting_agent_0_min": 0, "optimal_onion_potting_agent_0_max": 2, "optimal_onion_potting_agent_1_mean": 0.475, "optimal_onion_potting_agent_1_min": 0, "optimal_onion_potting_agent_1_max": 2, "optimal_tomato_potting_agent_0_mean": 0.75, "optimal_tomato_potting_agent_0_min": 0, "optimal_tomato_potting_agent_0_max": 3, "optimal_tomato_potting_agent_1_mean": 0.5, "optimal_tomato_potting_agent_1_min": 0, "optimal_tomato_potting_agent_1_max": 3, "viable_onion_potting_agent_0_mean": 0.175, "viable_onion_potting_agent_0_min": 0, "viable_onion_potting_agent_0_max": 2, "viable_onion_potting_agent_1_mean": 0.475, "viable_onion_potting_agent_1_min": 0, "viable_onion_potting_agent_1_max": 2, "viable_tomato_potting_agent_0_mean": 1.05, "viable_tomato_potting_agent_0_min": 0, "viable_tomato_potting_agent_0_max": 5, "viable_tomato_potting_agent_1_mean": 0.6, "viable_tomato_potting_agent_1_min": 0, "viable_tomato_potting_agent_1_max": 3, "catastrophic_onion_potting_agent_0_mean": 0.0, "catastrophic_onion_potting_agent_0_min": 0, "catastrophic_onion_potting_agent_0_max": 0, "catastrophic_onion_potting_agent_1_mean": 0.075, "catastrophic_onion_potting_agent_1_min": 0, "catastrophic_onion_potting_agent_1_max": 1, "catastrophic_tomato_potting_agent_0_mean": 0.05, "catastrophic_tomato_potting_agent_0_min": 0, "catastrophic_tomato_potting_agent_0_max": 1, "catastrophic_tomato_potting_agent_1_mean": 0.025, "catastrophic_tomato_potting_agent_1_min": 0, "catastrophic_tomato_potting_agent_1_max": 1, "useless_onion_potting_agent_0_mean": 0.0, "useless_onion_potting_agent_0_min": 0, "useless_onion_potting_agent_0_max": 0, "useless_onion_potting_agent_1_mean": 0.0, "useless_onion_potting_agent_1_min": 0, "useless_onion_potting_agent_1_max": 0, "useless_tomato_potting_agent_0_mean": 0.0, "useless_tomato_potting_agent_0_min": 0, "useless_tomato_potting_agent_0_max": 0, "useless_tomato_potting_agent_1_mean": 0.0, "useless_tomato_potting_agent_1_min": 0, "useless_tomato_potting_agent_1_max": 0}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458, 1.635813875194458, 182.0, 0.0, 53.63581387519446, 111.07489553315534, 35.233780012833535], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723, 55.53744776657767, 17.616890006416767], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723, 55.53744776657767, 17.616890006416767]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4114387140721217, "mean_inference_ms": 2.6956305328745462, "mean_action_processing_ms": 0.07920806144567069, "mean_env_wait_ms": 0.8929118893423957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 278.81855048053, "episode_reward_min": 0.0, "episode_reward_mean": 68.42640706452941, "episode_len_mean": 400.0, "episodes_this_iter": 2, "policy_reward_min": {"ppo": 0.0, "bc": 0.0}, "policy_reward_max": {"ppo": 139.409275240265, "bc": 139.409275240265}, "policy_reward_mean": {"ppo": 29.629110496647108, "bc": 42.726519169840266}, "hist_stats": {"episode_reward": [0.0, 1.635813875194458, 1.635813875194458, 119.17071671270779, 1.635813875194458, 1.7727697434322636, 1.635813875194458, 27.635813875194458, 41.48055623474042, 1.635813875194458, 119.17071671270779, 119.17071671270779, 21.26558037752801, 33.33179991303351, 22.815546597973167, 1.7906765085174356, 20.842395328015186, 53.63581387519446, 119.17071671270779, 247.00467177754845, 278.81855048053, 127.59348226516798, 127.59348226516798, 1.635813875194458, 85.66848476063993, 267.07489553315537, 157.73749162553793, 157.6358138751944, 1.635813875194458, 1.635813875194458, 27.635813875194458, 133.10133477025798, 1.635813875194458, 27.635813875194458, 1.635813875194458, 182.0, 0.0, 53.63581387519446, 111.07489553315534, 35.233780012833535], "episode_lengths": [400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400, 400], "policy_ppo_reward": [0.0, 0.0, 0.817906937597229, 0.817906937597229, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 0.817906937597229, 0.817906937597229, 0.8863848717161318, 0.8863848717161318, 0.817906937597229, 0.817906937597229, 13.817906937597229, 20.74027811737021, 20.74027811737021, 0.817906937597229, 0.817906937597229, 59.58535835635389, 59.58535835635389, 59.58535835635389, 10.632790188764005, 10.632790188764005, 16.665899956516753, 16.665899956516753, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723, 55.53744776657767, 17.616890006416767], "policy_bc_reward": [13.817906937597229, 59.58535835635389, 11.407773298986584, 0.8953382542587178, 10.421197664007593, 26.81790693759723, 59.58535835635389, 123.50233588877423, 139.409275240265, 63.79674113258399, 63.79674113258399, 0.817906937597229, 42.834242380319964, 133.53744776657766, 78.86874581276896, 78.81790693759721, 0.817906937597229, 0.817906937597229, 13.817906937597229, 66.55066738512899, 0.817906937597229, 13.817906937597229, 0.817906937597229, 91.0, 0.0, 26.81790693759723, 55.53744776657767, 17.616890006416767]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.4114387140721217, "mean_inference_ms": 2.6956305328745462, "mean_action_processing_ms": 0.07920806144567069, "mean_env_wait_ms": 0.8929118893423957, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 2, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 800, "num_env_steps_trained_this_iter": 800, "timesteps_total": 16000, "num_steps_trained_this_iter": 800, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 2280.234, "learn_time_ms": 9.867, "learn_throughput": 81082.06, "synch_weights_time_ms": 1.035}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 40, "training_iteration": 20, "trial_id": "default", "experiment_id": "d1f656109e80443ba21b09666f45dd57", "date": "2024-12-09_23-02-37", "timestamp": 1733745757, "time_this_iter_s": 4.045611381530762, "time_total_s": 47.53931379318237, "pid": 9680, "hostname": "HOME-BRYAN", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 400, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "overcooked_multi_agent", "env_config": {"mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}, "env_params": {"horizon": 400, "mlam_params": {"start_orientations": false, "wait_allowed": false, "counter_goals": [], "counter_drop": [], "counter_pickup": [], "same_motion_goals": true}}, "multi_agent_params": {"reward_shaping_factor": 1.0, "reward_shaping_horizon": Infinity, "use_phi": true, "bc_schedule": [[0.0, 0.0], [8000.0, 1.0], [Infinity, 1.0]]}, "outer_shape": null, "eval_mdp_params": {"layout_name": "asymmetric_advantages_tomato", "rew_shaping_params": {"PLACEMENT_IN_POT_REW": 3, "DISH_PICKUP_REWARD": 3, "SOUP_PICKUP_REWARD": 5, "DISH_DISP_DISTANCE_REW": 0, "POT_DISTANCE_REW": 0, "SOUP_DISTANCE_REW": 0}, "old_dynamics": false}}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_workers": 2, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "complete_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "train_batch_size": 800, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "evaluation_interval": 5, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": {}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": true, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB2C088>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001523B973148>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "off_policy_estimation_methods": {}, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "logger_creator": null, "logger_config": null, "log_level": "ERROR", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": true, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": -1, "min_iter_time_s": -1, "collect_metrics_timeout": -1, "buffer_size": -1, "prioritized_replay": -1, "learning_starts": -1, "replay_batch_size": -1, "replay_sequence_length": null, "prioritized_replay_alpha": -1, "prioritized_replay_beta": -1, "prioritized_replay_eps": -1, "min_time_s_per_reporting": -1, "min_train_timesteps_per_reporting": -1, "min_sample_timesteps_per_reporting": -1, "input_evaluation": -1, "lr_schedule": null, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 800, "num_sgd_iter": 1, "shuffle_sequences": true, "vf_loss_coeff": 0.0001, "entropy_coeff": 0.0, "entropy_coeff_schedule": [[0, 0.2], [300000.0, 0.1]], "clip_param": 0.05, "vf_clip_param": 10.0, "grad_clip": 0.1, "kl_target": 0.01, "vf_share_layers": true, "lambda": 0.98, "input": "sampler", "multiagent": {"policies": {"ppo": "<ray.rllib.policy.policy.PolicySpec object at 0x0000015217467988>", "bc": "<ray.rllib.policy.policy.PolicySpec object at 0x000001521DB43748>"}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x000001521D8B8EE8>", "policies_to_train": "{'ppo'}", "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "callbacks": "<class 'human_aware_rl.rllib.rllib.TrainingCallbacks'>", "create_env_on_driver": false, "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x000001521D8B8798>", "framework": "tf", "num_cpus_for_driver": 1}, "time_since_restore": 47.53931379318237, "timesteps_since_restore": 0, "iterations_since_restore": 20, "warmup_time": 14.182959079742432, "perf": {"cpu_util_percent": 26.839999999999996, "ram_util_percent": 76.0}}
